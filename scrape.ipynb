{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import feedparser\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from pymongo import MongoClient\n",
    "import os\n",
    "import pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the mongodb password from an environment variable\n",
    "mongoPass = os.environ['mongoPass']\n",
    "\n",
    "# Establish the remote connection to the mongo data base\n",
    "myclient = pymongo.MongoClient(\"mongodb+srv://axme100:{}@cluster0-5jopz.mongodb.net/test?retryWrites=true&w=majority\".format(mongoPass))\n",
    "\n",
    "# This is the name of the cluster stored on mongo atlas\n",
    "mydb = myclient[\"finalProject\"]\n",
    "\n",
    "# Create a new colection called raw article \n",
    "mycol = mydb[\"rawArticles\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the class that will be created\n",
    "class rawArticle:\n",
    "    def __init__(self, url, title, date, publication, articleText):\n",
    "        self.url = url\n",
    "        self.title = title\n",
    "        self.date = date\n",
    "        self.publication = publication\n",
    "        self.articleText = articleText\n",
    "        \n",
    "    def saveToDatabase(self):\n",
    "        # Save the entry into the mongo database\n",
    "        mycol.insert_one({'url': self.url,\n",
    "                         'title': self.title,\n",
    "                         'date': self.date,\n",
    "                         'publication': self.publication,\n",
    "                         'articleText': self.articleText})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a class of scraper\n",
    "class scraper:\n",
    "    \n",
    "    def scrape_jornada(self):\n",
    "        # Hard coded URL to be scraped\n",
    "        url=\"https://www.jornada.com.mx/rss/edicion.xml?v=1\"\n",
    "        \n",
    "        # Parse the XML feed\n",
    "        feedBurner = feedparser.parse(url)\n",
    "        \n",
    "        # Loop through all of the entries\n",
    "        for entry in feedBurner['entries']:\n",
    "    \n",
    "            # Get the page that we want to scrape\n",
    "            html = requests.get(entry['link'])\n",
    "        \n",
    "            # Save the page as a beautiful soup object\n",
    "            bs = BeautifulSoup(html.text, 'html.parser')\n",
    "    \n",
    "            articleText = bs.find(\"div\", {\"id\": \"article-text\"}).get_text().replace('\\n','').strip()\n",
    "    \n",
    "            # Create an article object\n",
    "            myArticle = rawArticle(url=entry['link'],\n",
    "                          title=entry['title'],\n",
    "                          date=entry['published'],\n",
    "                          publication=\"La Jornada\",\n",
    "                          articleText=articleText)\n",
    "        \n",
    "            # Call the object's method to save to a mongo data base\n",
    "            myArticle.saveToDatabase()\n",
    "    \n",
    "    def scrape_artistegui():\n",
    "        print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'get_text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-af34db573343>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmyScrapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscraper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmyScrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscrape_jornada\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-a9c6191a790c>\u001b[0m in \u001b[0;36mscrape_jornada\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mbs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'html.parser'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0marticleText\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"div\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"article-text\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;31m# Create an article object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'get_text'"
     ]
    }
   ],
   "source": [
    "myScrapper = scraper()\n",
    "myScrapper.scrape_jornada()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
